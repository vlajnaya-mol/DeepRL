{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report: Collaboration and Competition with MADDPG\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "The goal of this project is to train two reinforcement learning agents to play a game of tennis. The agents control rackets and must learn to hit a ball back and forth over a net. This is a multi-agent environment where the agents can be seen as both collaborating (to keep the rally going) and competing.\n",
    "\n",
    "The task is solved using a **Multi-Agent Deep Deterministic Policy Gradient (MADDPG)** algorithm, enhanced with techniques from **Twin-Delayed DDPG (TD3)** for improved stability. The environment is considered \"solved\" when the agents achieve an average score of **+0.5 over 100 consecutive episodes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learning Algorithm\n",
    "\n",
    "The algorithm implemented to solve this environment is the **Multi-Agent Deep Deterministic Policy Gradient (MADDPG)**. This is an actor-critic method that extends the DDPG algorithm to multi-agent settings, making it suitable for environments with both cooperative and competitive elements.\n",
    "\n",
    "### Key Concepts: MADDPG with TD3 Enhancements\n",
    "\n",
    "1.  **Centralized Training with Decentralized Execution (CTDE)**: This is the core idea behind MADDPG.\n",
    "    *   **Centralized Training**: During training, a centralized **critic** for each agent has access to the observations and actions of *all* agents. This global perspective allows the critic to learn a stable and accurate Q-function, even though the environment is non-stationary from the perspective of any single agent (since other agents' policies are also changing).\n",
    "    *   **Decentralized Execution**: During execution (acting in the environment), each agent's **actor** only uses its own local observations to select an action. This is practical for real-world scenarios where agents may not have access to global information.\n",
    "\n",
    "2.  **Independent Agents**: The implementation consists of two independent DDPG agents, each with its own actor and critic networks. However, they share a common experience replay buffer.\n",
    "\n",
    "3.  **TD3 Enhancements for Stability**: To improve upon the stability of DDPG, this implementation incorporates key features from the **Twin-Delayed DDPG (TD3)** algorithm:\n",
    "    *   **Clipped Double-Q Learning**: Two critic networks are used for each agent. When calculating the target Q-value for the Bellman update, the *minimum* of the two critics' predictions is used. This helps to mitigate the overestimation bias commonly found in Q-learning methods.\n",
    "    *   **Target Policy Smoothing**: Noise is added to the target action during the critic update. This smooths the value function and makes the policy less likely to exploit narrow peaks in the Q-function.\n",
    "    *   **Delayed Policy Updates**: The actor (policy) and target networks are updated less frequently than the critic networks. This allows the critic's value estimate to stabilize before the policy is updated, leading to more stable training.\n",
    "\n",
    "### Model Architectures\n",
    "\n",
    "**Actor Network** (for each agent)\n",
    "*   **Input Layer**: 24 units (State Size)\n",
    "*   **Hidden Layer 1**: 256 units (with ReLU activation)\n",
    "*   **Hidden Layer 2**: 128 units (with ReLU activation)\n",
    "*   **Output Layer**: 2 units (Action Size, with Tanh activation)\n",
    "\n",
    "**Critic Network** (for each agent, two critics per agent for TD3)\n",
    "The critic takes the combined states and actions of *all* agents as input.\n",
    "*   **Input Layer (States)**: 48 units (24 per agent * 2 agents) -> **Hidden Layer 1**: 256 units (with Leaky ReLU)\n",
    "*   **Concatenation**: The output is concatenated with the combined action vector (4 units total).\n",
    "*   **Hidden Layer 2**: 256 units (with Leaky ReLU)\n",
    "*   **Hidden Layer 3**: 128 units (with Leaky ReLU)\n",
    "*   **Output Layer**: 1 unit (Q-value)\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "| Hyperparameter            | Value           | Description                                                        |\n",
    "| ------------------------- | --------------- | ------------------------------------------------------------------ |\n",
    "| `BUFFER_SIZE`             | 1e6             | Replay buffer size                                                 |\n",
    "| `BATCH_SIZE`              | 256             | Minibatch size                                                     |\n",
    "| `GAMMA`                   | 0.99            | Discount factor                                                    |\n",
    "| `TAU`                     | 1e-3            | Soft update parameter for target networks                          |\n",
    "| `LR_ACTOR`                | 1e-4            | Learning rate for the actor optimizer                              |\n",
    "| `LR_CRITIC`               | 3e-4            | Learning rate for the critic optimizer                             |\n",
    "| `WEIGHT_DECAY`            | 0               | L2 weight decay                                                    |\n",
    "| `NOISE_SIGMA`             | 0.2             | Ornstein-Uhlenbeck noise `sigma` parameter                         |\n",
    "| `UPDATE_EACH`             | 1               | Update the network every 1 time step                               |\n",
    "| `UPDATES_PER_STEP`        | 1               | Perform 1 update per time step                                     |\n",
    "| `TD3_DELAY`               | 2               | Delay policy updates by 2 critic updates                           |\n",
    "| `TARGET_POLICY_NOISE`     | 0.2             | Stddev of noise for target policy smoothing                        |\n",
    "| `NOISE_CLIP`              | 0.5             | Clip for target policy smoothing noise                             |\n",
    "| `n_episodes`              | 3200            | Maximum number of training episodes                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "### 0. Prerequisites\n",
    "\n",
    "Follow environment creation and dependecy installation guidelines from the README.md file\n",
    "\n",
    "### 1. Start the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/olehborovyk/Code/drlnd\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(1)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), \"DeepRL\", \"MADDPG\", \"Tennis.app\")\n",
    "env = UnityEnvironment(file_name=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MADDPG Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from DeepRL.MADDPG.maddpg import MADDPG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED); torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "agent = MADDPG(\n",
    "    state_size=24,\n",
    "    action_size=2,\n",
    "    n_agents=2,\n",
    "    random_seed=RANDOM_SEED,\n",
    "\n",
    "    # replay / batch\n",
    "    buffer_size=int(1e6),\n",
    "    batch_size=256,\n",
    "\n",
    "    # RL\n",
    "    gamma=0.99,\n",
    "    tau=1e-3,\n",
    "\n",
    "    # optim\n",
    "    lr_actor=1e-4,\n",
    "    lr_critic=3e-4,\n",
    "    weight_decay=0,\n",
    "\n",
    "    noise_mu=0.0,\n",
    "    noise_theta=0.15,\n",
    "    noise_sigma=0.2,\n",
    "\n",
    "    # update cadence\n",
    "    warmup_steps=1000,\n",
    "    update_each=1,\n",
    "    updates_per_step=1,\n",
    "\n",
    "    # TD3 bits\n",
    "    td3_critic=True,\n",
    "    td3_delay=2,\n",
    "    target_policy_noise=0.2,\n",
    "    noise_clip=0.5,\n",
    ")\n",
    "n_episodes = 4_000\n",
    "avg_score_over_k_episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 100/4000 [00:27<47:55,  1.36it/s, Ep. score=0.000] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 200/4000 [01:38<38:48,  1.63it/s, Ep. score=0.000]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 300/4000 [02:38<37:37,  1.64it/s, Ep. score=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 400/4000 [03:40<38:33,  1.56it/s, Ep. score=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 500/4000 [04:41<36:42,  1.59it/s, Ep. score=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 600/4000 [05:42<33:40,  1.68it/s, Ep. score=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 700/4000 [07:05<34:34,  1.59it/s, Ep. score=0.000]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 800/4000 [08:18<53:39,  1.01s/it, Ep. score=0.100]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 900/4000 [10:04<1:07:12,  1.30s/it, Ep. score=0.100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1000/4000 [11:45<33:39,  1.49it/s, Ep. score=0.000] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1100/4000 [13:12<48:19,  1.00it/s, Ep. score=0.090]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1200/4000 [14:29<30:10,  1.55it/s, Ep. score=0.000]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 1300/4000 [15:45<48:05,  1.07s/it, Ep. score=0.000]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 1400/4000 [17:08<27:44,  1.56it/s, Ep. score=0.000]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1500/4000 [19:26<29:54,  1.39it/s, Ep. score=0.000]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1600/4000 [21:20<45:14,  1.13s/it, Ep. score=0.000]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 1700/4000 [23:29<45:27,  1.19s/it, Ep. score=0.090]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1800/4000 [26:01<1:23:11,  2.27s/it, Ep. score=0.090]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1900/4000 [28:44<1:00:34,  1.73s/it, Ep. score=0.090]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2000/4000 [31:19<45:53,  1.38s/it, Ep. score=0.100]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 2100/4000 [34:27<1:06:55,  2.11s/it, Ep. score=0.100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2200/4000 [36:58<45:53,  1.53s/it, Ep. score=0.100]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 2300/4000 [39:39<36:43,  1.30s/it, Ep. score=0.100]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2400/4000 [42:29<31:41,  1.19s/it, Ep. score=0.100]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 2500/4000 [45:33<49:13,  1.97s/it, Ep. score=0.090]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 2600/4000 [50:52<1:48:50,  4.66s/it, Ep. score=0.400]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2700/4000 [55:44<1:10:17,  3.24s/it, Ep. score=0.200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 2800/4000 [1:00:31<45:19,  2.27s/it, Ep. score=0.100]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 2900/4000 [1:06:27<1:18:54,  4.30s/it, Ep. score=0.100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3000/4000 [1:16:05<1:46:01,  6.36s/it, Ep. score=0.100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3100/4000 [1:28:58<1:47:37,  7.17s/it, Ep. score=0.600]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3137/4000 [1:33:16<2:25:50, 10.14s/it, Ep. score=1.100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEM SOLVED! Achieved 0.5034 score over the last 100 episodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 3200/4000 [1:44:26<2:56:03, 13.20s/it, Ep. score=0.600]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 3300/4000 [2:08:48<3:23:34, 17.45s/it, Ep. score=1.100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. score over last 100 episodes: 0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 3326/4000 [2:16:25<27:38,  2.46s/it, Ep. score=2.600]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at episode 3325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores_deque = deque(maxlen=avg_score_over_k_episodes)                       \n",
    "all_scores = []\n",
    "all_actions = []\n",
    "max_score = -1\n",
    "\n",
    "with tqdm(total=n_episodes) as pbar:\n",
    "    for episode in range(n_episodes):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]  \n",
    "        agent.reset(progress=episode/n_episodes)\n",
    "        \n",
    "        states = env_info.vector_observations   \n",
    "        episode_scores = np.zeros(num_agents)\n",
    "        dones = [0, 0]\n",
    "        while not np.any(dones):\n",
    "            actions = agent.act(states, add_noise=True)\n",
    "            actions = np.array(actions)\n",
    "            all_actions.append(actions)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            episode_scores += rewards\n",
    "            states = next_states\n",
    "            \n",
    "        episode_scores = [episode_scores.max()]\n",
    "        scores_deque.extend(list(episode_scores))\n",
    "        all_scores.extend(list(episode_scores))\n",
    "        \n",
    "        avg_score = np.mean(scores_deque)\n",
    "        \n",
    "        if episode % avg_score_over_k_episodes == avg_score_over_k_episodes-1:\n",
    "            print(f\"Avg. score over last {avg_score_over_k_episodes} episodes: {avg_score:.3f}\")\n",
    "        pbar.set_postfix({\"Ep. score\": f\"{episode_scores[0]:.3f}\"})\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if avg_score >= 0.5 and episode >= avg_score_over_k_episodes:\n",
    "            if max_score < 0.5:\n",
    "                print(f\"PROBLEM SOLVED! Achieved {avg_score:.4f} score over the last {avg_score_over_k_episodes} episodes\")\n",
    "            if avg_score > max_score:\n",
    "                max_score = avg_score\n",
    "                for i, ag in enumerate(agent.agents):\n",
    "                    torch.save(ag.actor_local.state_dict(), os.path.join(os.getcwd(), \n",
    "                                                                         \"DeepRL\", \"MADDPG\", \"checkpoints\", f'checkpoint_actor_{i}.pth'))\n",
    "                    torch.save(ag.critic_local.state_dict(), os.path.join(os.getcwd(), \n",
    "                                                                         \"DeepRL\", \"MADDPG\", \"checkpoints\", f'checkpoint_critic_{i}.pth'))\n",
    "                    torch.save(ag.td3_critic_local.state_dict(), os.path.join(os.getcwd(), \n",
    "                                                                         \"DeepRL\", \"MADDPG\", \"checkpoints\",  f'checkpoint_td3_critic_{i}.pth'))\n",
    "            if avg_score >= 1.0:\n",
    "                print(f\"Early stop at episode {episode}\")\n",
    "                break\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Results\n",
    "\n",
    "The MADDPG agent was successful in solving the environment.\n",
    "\n",
    "The environment was solved in 3200 episodes, achieving an average score of over +0.5 across 100 consecutive episodes.\n",
    "\n",
    "The plot above shows the score for each episode, with the orange line representing the 100-episode moving average. The score initially fluctuates but shows a clear upward trend, eventually surpassing the +0.5 target (red dashed line) and remaining there, indicating a stable and successful learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(all_scores)+1), all_scores, label='Episode Score')\n",
    "# Add a 100-episode moving average\n",
    "rolling_mean = pd.Series(all_scores).rolling(avg_score_over_k_episodes).mean()\n",
    "plt.plot(rolling_mean, label='100-episode Average', color='orange')\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='Target Score (0.5)')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.title('Scores per Episode during Training')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ideas for Future Work\n",
    "\n",
    "While the MADDPG+TD3 agent performed well, several areas could be explored for further improvement:\n",
    "\n",
    "1.  **Prioritized Experience Replay (PER)**: Instead of uniform sampling, PER could be used to train more frequently on \"surprising\" or high-error transitions. This could be adapted for the multi-agent case to improve sample efficiency.\n",
    "\n",
    "2.  **Alternative Noise Strategies**: The Ornstein-Uhlenbeck process provides temporally correlated noise. It would be interesting to compare its performance with simpler, uncorrelated Gaussian noise or parameter space noise, which sometimes yields better results.\n",
    "\n",
    "3.  **Hyperparameter Optimization**: A more rigorous search for hyperparameters (e.g., using grid search or Bayesian optimization) could potentially find a configuration that allows the agents to learn even faster or achieve a higher peak performance.\n",
    "\n",
    "4.  **Exploration of Other Multi-Agent Algorithms**: It would be valuable to implement and compare the performance of other modern multi-agent algorithms, such as **Proximal Policy Optimization for Multi-Agent settings (MA-PPO)**, which is known for its stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/olehborovyk/Code/drlnd\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score this episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "# --- NOTE ---\n",
    "# You may need to restart the kernel and re-run the environment setup cell\n",
    "# before executing the inference code below.\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import torch, os\n",
    "import numpy as np\n",
    "from DeepRL.MADDPG.maddpg import MADDPG\n",
    "\n",
    "# Re-initialize environment\n",
    "path = os.path.join(os.getcwd(), \"DeepRL\", \"MADDPG\", \"Tennis.app\")\n",
    "env = UnityEnvironment(file_name=path)\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "# Get environment parameters\n",
    "action_size = brain.vector_action_space_size\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "num_agents = len(env_info.agents)\n",
    "\n",
    "# Initialize a new agent\n",
    "RANDOM_SEED = 4252\n",
    "np.random.seed(RANDOM_SEED); torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "agent = MADDPG(\n",
    "    state_size=24,\n",
    "    action_size=2,\n",
    "    n_agents=2,\n",
    "    random_seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "for i, ag in enumerate(agent.agents):\n",
    "    ag.actor_local.load_state_dict(torch.load(os.path.join(os.getcwd(), \"DeepRL\", \"MADDPG\", \"checkpoints\", f'checkpoint_actor_{i}.pth')))\n",
    "    ag.critic_local.load_state_dict(torch.load(os.path.join(os.getcwd(), \"DeepRL\", \"MADDPG\", \"checkpoints\", f'checkpoint_critic_{i}.pth')))\n",
    "    ag.td3_critic_local.load_state_dict(torch.load(os.path.join(os.getcwd(), \"DeepRL\", \"MADDPG\", \"checkpoints\", f'checkpoint_td3_critic_{i}.pth')))\n",
    "\n",
    "scores = np.zeros(num_agents)\n",
    "while True:\n",
    "    actions = agent.act(states, add_noise=False)\n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    next_states = env_info.vector_observations\n",
    "    rewards = env_info.rewards\n",
    "    dones = env_info.local_done\n",
    "    scores += env_info.rewards\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "\n",
    "print('Total score this episode: {}'.format(np.max(scores)))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
